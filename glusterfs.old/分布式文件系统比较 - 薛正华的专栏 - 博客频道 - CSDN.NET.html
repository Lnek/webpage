<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>分布式文件系统比较 - 薛正华的专栏 - 博客频道 - CSDN.NET</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="description" content="分布式文件系统MFS、Ceph、GlusterFS、Lustre的比较http://blog.prosight.me/index.php/2011/12/848http://shen2.cn/2010/08/distributed-filesystems/http://os.51cto.com/art/201011/233441.htm" />
<script src="http://static.blog.csdn.net/scripts/jquery.js" type="text/javascript"></script>
<script type="text/javascript" src="http://static.blog.csdn.net/scripts/ad.js?v=1.1"></script>
<link rel="Stylesheet" type="text/css" href="http://static.blog.csdn.net/skin/light_blue/css/style.css?v=1.1" />
<link id="RSSLink" title="RSS" type="application/rss+xml" rel="alternate" href="/zhxue123/rss/list" />
<link rel="shortcut icon" href="/favicon.ico" />
<link type="text/css" rel="stylesheet" href="http://static.blog.csdn.net/scripts/SyntaxHighlighter/styles/default.css" />
</head>
<body>
<script src="http://csdnimg.cn/pubnav/js/pub_topnav_2011.js"type="text/javascript"></script>

<div id="container">
<div id="header">
    <div class="header">
        <div id="blog_title">
            <h1><a href="http://blog.csdn.net/zhxue123">薛正华的专栏</a></h1>
            <h2></h2>
            <div class="clear"></div>
        </div>
        <div class="clear"></div>
    </div>
</div>
<div id="navigator">
    <div class="navigator_bg"></div>
    <div class="navigator">
        <ul>
            <li id="btnContents"><a href="http://blog.csdn.net/zhxue123?viewmode=contents"><span><img src="http://static.blog.csdn.net/images/ico_list.gif">目录视图</span></a></li>
            <li id="btnView"><a href="http://blog.csdn.net/zhxue123?viewmode=list"><span><img src="http://static.blog.csdn.net/images/ico_summary.gif">摘要视图</span></a></li>
            <li id="btnRss"><a href="http://blog.csdn.net/zhxue123/rss/list"><span><img src="http://static.blog.csdn.net/images/ico_rss.gif">订阅</span></a></li>
</ul>
    </div>
</div>
<script type="text/javascript">
    var username = "zhxue123";
    var _blogger = username;
    var blog_address = "http://blog.csdn.net/zhxue123";
    var static_host = "http://static.blog.csdn.net";
    var currentUserName = "";
</script>

<div id="body">
<div id="main">
<div class="main">
<div class="notice"> 

<a href="http://blog.csdn.net/blogdevteam/article/details/9819385" target="_blank">
<font color=red>《这些年，我们读过的技术经典图书》主题有奖征文</font></a>



&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<a href="http://www.csdn.net/article/2013-08-06/2816471" target="_blank"><font color=blue>专访李铁军：从医生到金山首席安全专家的转变 
</font></a>

&nbsp;&nbsp;&nbsp;&nbsp;



<a href="http://blog.csdn.net/adali/article/details/9813651"target="_blank">
<font color=blue>独一无二的职位：开源社区经理 
 </font></a>




</div>
<div id="article_details" class="details">
    <div class="article_title">
    <span class="ico ico_type_Original"></span>
    <h3>
        <span class="link_title"><a href="/zhxue123/article/details/7951636">
        分布式文件系统比较
        </a></span>
    </h3>
</div>

        
    <div class="article_manage">
        <span class="link_categories">
        分类：
            <a href="/zhxue123/article/category/1181998">CloudComputing</a> 
        </span>
    <span class="link_postdate">2012-09-06 16:59</span>
    <span class="link_view" title="阅读次数">422人阅读</span>
    <span class="link_comments" title="评论次数"><a href="#comments">评论</a>(0)</span>
    <span class="link_collect"><a href="javascript:void(0);" onclick="javascript:collectArticle('分布式文件系统比较','7951636');return false;" title="收藏">收藏</a></span>
    <span class="link_report"><a href="#report"  onclick="javascript:report(7951636,2);return false;" title="举报">举报</a></span>
    
</div>


    
<div id="article_content" class="article_content">

<p><br>
</p>
<p></p>
<h2 class="topTitle" style="margin:0px; padding:10px 0px; font-family:Verdana"><a href="http://blog.prosight.me/index.php/2011/12/848" style="margin:0px; padding:0px; text-decoration:none"><span style="font-size:12px; color:#000000">分布式文件系统MFS、Ceph、GlusterFS、Lustre的比较</span></a></h2>
<br>
<p></p>
<p><a href="http://blog.prosight.me/index.php/2011/12/848">http://blog.prosight.me/index.php/2011/12/848</a></p>
<p><br>
</p>
<p><br>
</p>
<p><a href="http://shen2.cn/2010/08/distributed-filesystems/">http://shen2.cn/2010/08/distributed-filesystems/</a><br>
</p>
<p><br>
</p>
<p><br>
</p>
<p><a href="http://os.51cto.com/art/201011/233441.htm">http://os.51cto.com/art/201011/233441.htm</a><br>
</p>
<p><br>
</p>
<p>Gluster集群文件系统研究</p>
<p><a href="http://blog.csdn.net/liuben/article/details/6284551">http://blog.csdn.net/liuben/article/details/6284551</a><br>
</p>
<p>如下功能：</p>
<p></p>
<ul>
<li>Gluster的Geo-replication可以实现跨LAN，WAN， and across the internet。这为多数据中心的数据同步提供了保障。</li><li>Existing map-reduce apps can use GlusterFS seamlessly.</li><li>能够跑在Infiniband上，支持RDMA</li><li>Red Hat recommends XFS when formatting the disk sub-system，Any other POSIX compliant disk file system, such as Ext3, Ext4, ReiserFS may also work, but has not<br>
been tested widely.</li><li><br>
</li><li>GLuster有以下角色：
<ul>
<li>并行文件系统</li><li>卷(云硬盘，可挂载到虚拟机)</li><li>对象存储(云存储)</li></ul>
</li></ul>
<p></p>
<p>考虑到Gluster不同模式针对的场景有所不同，方案应该针对不同的读写场景（文件大小，并发访问量）等，制定不同的策略。</p>
<p><br>
</p>
<p><strong>Striped</strong>： 把一个数据划分为几个数据集（把大数据分成100个数据块，划到StripedNum个数据集中）不是大数据最好别做，放在一个地方存Cache命中率高。<span style="color:rgb(255,0,0)">StripedNum = BricksNum</span></p>
<p><span style="color:#3366ff">gluster volume create test-volume stripe 2 <span style="color:rgb(51,102,255)">
transport tcp&nbsp;</span>server1:/exp1 server2:/exp2</span></p>
<p><br>
</p>
<p><strong>Distributed Striped</strong>：文件在一个Server内部的不同bricks做条带化，尽量 把不同文件放在不同的Server上。<span style="color:#ff0000">N *&nbsp;</span><span style="color:rgb(255,0,0)">StripedNum = BricksNum</span></p>
<p><span style="color:#3366ff">gluster volume create test-volume stripe 4 transport tcp server1:/exp1 server2:/exp2 server3:/exp3&nbsp;<span style="color:rgb(51,102,255)">server4:/exp4 server5:/exp5 server6:/exp6&nbsp;<span style="color:rgb(51,102,255)">server7:/exp7&nbsp;<span style="color:rgb(51,102,255)">server8:/exp8</span></span></span></span></p>
<p><br>
</p>
<p><strong>Replicated</strong>：高可用（文件在不同的Server上有副本）；有副本后可以提高读性能&nbsp;<span style="color:rgb(255,0,0)">&nbsp;</span><span style="color:rgb(255,0,0)">ReplicatedNum = BricksNum &nbsp;？</span><br>
</p>
<p><span style="color:rgb(51,102,255)">gluster volume create test-volume replica 2&nbsp;</span><span style="color:rgb(51,102,255)">transport tcp&nbsp;</span><span style="color:rgb(51,102,255)">server1:/exp1 server2:/exp2</span></p>
<p><strong><br>
</strong></p>
<p><strong>Distributed Replicated</strong>：高可用（文件在不同的Server上有副本）；有副本后可以提高读性能&nbsp;&nbsp;<span style="color:#ff0000">N *&nbsp;</span><span style="color:rgb(255,0,0)">ReplicatedNum = BricksNum</span></p>
<p><span style="color:rgb(51,102,255)">gluster volume create test-volume replica 2&nbsp;</span><span style="color:rgb(51,102,255)">transport tcp&nbsp;</span><span style="color:rgb(51,102,255)">server1:/exp1 server2:/exp2&nbsp;<span style="color:rgb(51,102,255)">server3:/exp3&nbsp;</span><span style="color:rgb(51,102,255)">server4:/exp4</span></span><br>
</p>
<p><br>
</p>
<p><strong>Striped Replicated</strong>：for MapReduce任务，一个文件打碎后，文件块在多个Server上 <span style="color:rgb(255,0,0)">
&nbsp;<span style="color:rgb(255,0,0)">StripedNum *&nbsp;</span></span><span style="color:rgb(255,0,0)">ReplicatedNum = BricksNum&nbsp;</span><br>
</p>
<p><br>
</p>
<p><strong>Distributed Striped Replicated</strong>：for MapReduce任务，一个文件打碎后，文件块在多个Server上 &nbsp;<span style="color:rgb(255,0,0)">N*</span><span style="color:rgb(255,0,0)">StripedNum *&nbsp;</span><span style="color:rgb(255,0,0)">ReplicatedNum = BricksNum</span></p>
<p><span style="color:rgb(255,0,0)"><br>
</span></p>
<p><span style="color:#ff0000">划分为多个Stripe能增加，如果本地磁盘读写800MB，而单节点网络带宽只有100MB，那么网络带宽是瓶颈，应该划分Stripe</span></p>
<p><span style="color:#ff0000">从目前看来，划volume是由管理员指定bricks，那么这是不是没有实现自动负载均衡？</span></p>
<p><br>
</p>
<p>具体任务：</p>
<p></p>
<ul>
<li>用户管理如何解决（虚拟机的用户和文件系统的用户如何统一）</li><li>能否提供块存储？如何给用户分配云硬盘，提供volume时，用户用的话需要fdisk&#26684;盘，支持几种文件系统&#26684;式？
<ul>
<li>1）块存储可以用盘阵（SAN），实验一下OpenStack是否像VCenter一样直接支持卷的分配。</li><li><br>
</li></ul>
</li><li>测试物理机的性能，虚拟机的访问性能</li><li>负载均衡是自动的吗？考虑到划volume是人工进行的，如果不是如何保障？</li><li>需要不断调优，拿出很好的测试数据来匹配好机器。</li><li>如何实现可伸缩性（用户的卷可以手动调整，继而可以动态变化）</li><li><br>
</li><li><br>
</li></ul>
<p></p>
<p><br>
</p>
<p>Server：201-204， &nbsp; port：241.101<br>
</p>
<p><br>
</p>
<p>Gluster安装配置（CentOS，）</p>
<p><br>
</p>
<p>一、安装</p>
<p>参考Installation_Guide</p>
<p>1.Install required prerequisites on the server using the following command</p>
<p><span style="white-space:pre"></span>yum -y install wget fuse fuse-libs</p>
<p>2.&nbsp;Download the latest GlusterFS core and FUSE RPM files to each server in your cluster</p>
<p></p>
<p>(1)在<a href="http://bits.gluster.com/pub/gluster/glusterfs/3.3.0/x86_64/">http://bits.gluster.com/pub/gluster/glusterfs/3.3.0/x86_64/</a>&nbsp;下载</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;glusterfs-3.3.0-1.x86_64.rpm&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; glusterfs-fuse-3.3.0-1.x86_64.rpm&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; glusterfs-geo-replication-3.3.0-1.x86_64.rpm&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; glusterfs-server-3.3.0-1.x86_64.rpm</p>
<p>&nbsp;</p>
<p>安装glusterfs-3.3.0-1.x86_64.rpm时候如果报出如下的错误：</p>
<p>执行：#&gt;yum install openssl098e</p>
<p>安装&nbsp;&nbsp;&nbsp;&nbsp; glusterfs-server-3.3.0-1.x86_64.rpm如果报出如下的错误：</p>
<p>&nbsp;</p>
<p>执行：#&gt;yum install compat-readline5 compat-libtermcap</p>
<br>
<p>3.使用xfs&#26684;式化文件系统</p>
<p>[root@localhost zhxue]# yum install -y &nbsp;xfs，如果报错，执行<br>
</p>
<p><br>
</p>
<p>yum install -y &nbsp;xfs*<br>
</p>
<p><br>
</p>
<p><strong>二、配置</strong></p>
<p><strong>1、启动服务</strong>（用chkconfig加入系统服务启动列表中，开机自动启动）</p>
<p>[root@serv202 ~]# /etc/init.d/glusterd start; chkconfig glusterd on<br>
</p>
<p><strong>2、创建节点信任池</strong></p>
<p>gluster peer probe server1</p>
<p>gluster peer probe server2<br>
</p>
<p>gluster peer probe server3<br>
</p>
<p>gluster peer probe server4<br>
</p>
<p>若遇到下面情况，可参考下面方案解决</p>
<p><br>
</p>
<p>[root@localhost zhxue]# gluster peer probe gluster002<br>
Probe unsuccessful<br>
Probe returned with unknown errno 107<br>
</p>
<p><br>
</p>
<p></p>
<div>&nbsp;看看下面这个文件：<br>
cat&nbsp;var/log/glusterfs/etc-glusterfs-glusterd.vol.log&nbsp;</div>
<br>
<p></p>
<p>发现 no route to server2</p>
<p><br>
</p>
<p>想到节点之间是互通的，估计是防火墙阻碍了gluster相关端口，关闭后即可。当然最好是打开对应的端口，而不要关掉整个防火墙。</p>
<p><br>
</p>
<p><strong>3、创建卷</strong><br>
</p>
<p>[root@gluster001 ~]# gluster volume create volsdb &nbsp;replica 2 transport tcp gluster001:/sdb &nbsp;gluster002:/sdb gluster003:/sdb gluster004:/sdb<br>
Creation of volume volsdb has been successful. Please start the volume to access data.<br>
</p>
<p><strong><br>
</strong></p>
<p><strong>[root@gluster001 ~]# gluster volume info<br>
&nbsp;<br>
Volume Name: volsdb<br>
Type: Distributed-Replicate<br>
Volume ID: 7189d2f7-db94-4b79-9a22-87b9814672ec<br>
Status: Created<br>
Number of Bricks: 2 x 2 = 4<br>
Transport-type: tcp<br>
Bricks:<br>
Brick1: gluster001:/sdb<br>
Brick2: gluster002:/sdb<br>
Brick3: gluster003:/sdb<br>
Brick4: gluster004:/sdb<br>
</strong></p>
<p></p>
<p><strong>4、启动卷并挂载</strong><br>
</p>
<p>在服务器端：[root@gluster001 ~]# gluster volume start volsdb</p>
<p>在客户端：&nbsp;sudo mount -t glusterfs gluster001:/volsdb /mnt/zhxue</p>
<p>挂载成功后，发现/mnt/zhxue的容量只有500&#43;GB，一直不明白原因，重挂载几次后问题依旧。后来发现，在gluster002-gluster004上没有把磁盘挂上来，即忘了mount &nbsp;/dev/sdf等设备到本地磁盘/localdisk/sdf。相当于只有一个节点在服务。</p>
<p>后来正确执行后，不用再重新建卷或停止、启动卷，看到了8T的目录大小。挺智能，还不错。</p>
<p><span style="font-weight:bold"><br>
</span></p>
<p><span style="font-weight:bold">5、删除卷</span><br>
</p>
<p><span style="font-weight:bold">先停止，再删</span></p>
<p>[root@gluster001 ~]# gluster volume stop &nbsp;volsdd-test<br>
</p>
<p>停止后，客户端df命令，看不到所挂载的卷了。但用mount或cat /proc/mounts<span style="white-space:pre"> </span>
还是能看到挂载。</p>
<p>此时，如果再启动被停止的卷。df命令就可以看到磁盘了，不需要重新挂载（这是因为mount点并没有被撤销）</p>
<p><br>
</p>
<p>[root@gluster001 ~]# gluster volume delete &nbsp;volsdd-test<br>
</p>
<p>如果删除了，客户端还是df看不到，mount可以看到。客户端只好umount，一切正常。</p>
<p><br>
</p>
<p><span style="font-weight:bold">6、删除卷</span></p>
<p><br>
</p>
<p>root@new-2:/home/ubuntu# dd if=/dev/zero &nbsp;of=/mnt/10gfile bs=1MB count=1024x10<br>
10240&#43;0 records in<br>
10240&#43;0 records out<br>
10240000000 bytes (10 GB) copied, 392.422 s, 26.1 MB/s<br>
</p>
<p><br>
</p>
root@new-1:/home/ubuntu# dd if=/dev/zero &nbsp;of=/1gfile bs=1MB count=1024x1<br>
1024&#43;0 records in<br>
1024&#43;0 records out<br>
<p>1024000000 bytes (1.0 GB) copied, 34.7465 s, 29.5 MB/s</p>
<p><br>
</p>
<p><br>
</p>
<p>&nbsp;setfattr -x trusted.glusterfs.volume-id /localdisk/sdc/rep4; setfattr -x trusted.gfid /localdisk/sdc/rep4; rm -rf /localdisk/sdc/rep4/.glusterfs；&nbsp;setfattr -x trusted.glusterfs.volume-id /localdisk/sdd/rep4; setfattr -x trusted.gfid /localdisk/sdd/rep4;
 rm -rf /localdisk/sdd/rep4/.glusterfs;&nbsp;&nbsp;setfattr -x trusted.glusterfs.volume-id /localdisk/sdb/rep4; setfattr -x trusted.gfid /localdisk/sdb/rep4; rm -rf /localdisk/sdb/rep4/.glusterfs<br>
</p>
<p><br>
</p>
<p><br>
</p>
<p><br>
</p>
<p><strong>7.测试结果</strong></p>
<p>7.1、<strong>性能测试</strong></p>
<p>root@ubuntuDell:/home/yongyou# dd if=/dev/zero of=/mnt/50g bs=1MB count=1024x50<br>
51200&#43;0 records in<br>
51200&#43;0 records out<br>
51200000000 bytes (51 GB) copied, 461.971 s, 111 MB/s<br>
root@ubuntuDell:/home/yongyou# dd if=/dev/zero of=/var/lib/nova/instances/50g bs=1MB count=1024x50<br>
51200&#43;0 records in<br>
51200&#43;0 records out<br>
51200000000 bytes (51 GB) copied, 994.198 s, 51.5 MB/s<br>
</p>
<p><strong>物理机直接挂在gluster上，没有replica时是110MB基本满带宽，replica=2是50MB，replica=3是34MB，线性递减</strong></p>
<p><strong>答案：gluster把所有事情交给客户端了，当rep=2时，其实客户端在向两个gluster server努力写数据，客户端的实际网络流量是100MB，dd命令的带宽计算是根据文件大小除以传输时间，所以看&#20284;性能减半。本质是因为客户端传输了2倍的文件量。要想摆平这个问题，只能改写客户端的模式，即让客户端只向一个server写，被写server自己去向server做副本，把写副本事务转嫁给后台gluster服务器。但是这样做会有一个坏处，<span style="color:#ff0000">就是无法保障两个副本严&#26684;的一致性</span>。</strong></p>
<p><strong><br>
</strong></p>
<p><strong>还发现一个问题，当replica=3时，3个副本在一台机器上，这是相当危险的！！！我们创建副本的脚本如下：</strong></p>
<p>gluster volume create volsdg &nbsp;replica 3 transport tcp gluster001:/localdisk/sdg/test4 gluster001:/localdisk/sdg/test5 &nbsp; gluster001:/localdisk/sdg/test6 gluster002:/localdisk/sdg/test4 gluster002:/localdisk/sdg/test5 &nbsp;gluster002:/localdisk/sdg/test6 gluster003:/localdisk/sdg/test4
 gluster003:/localdisk/sdg/test5 &nbsp;gluster003:/localdisk/sdg/test6 gluster004:/localdisk/sdg/test4 gluster004:/localdisk/sdg/test5 gluster004:/localdisk/sdg/test6</p>
<p><strong>上述问题把节点依次错开就没事了，可能后端是轮询算法吧？？？</strong></p>
<p><strong><br>
</strong></p>
<p><strong>虚拟机挂载在gluster上，对自己的某个目录进行写，所挂目录replica=2，虚拟机内存8G:</strong></p>
<p><strong>5G文件 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1MB块大小 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 30.7MB/s （写） &nbsp; 620MB（读）</strong></p>
<p><strong>10G文件 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1MB块大小 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 26.7MB/s &nbsp; （写） &nbsp; 60MB/s(读)</strong></p>
<p><br>
</p>
<p><strong>使用raid10（raid0：stripe 2 &nbsp;； raid1 replica 2）模式做实验的测试结果如下：</strong></p>
<p>gluster volume create volsdg stripe 2 &nbsp;replica 2 transport tcp gluster001:/localdisk/sdg &nbsp;gluster002:/localdisk/sdg gluster003:/localdisk/sdg gluster004:/localdisk/sdg<br>
</p>
<p><span style="font-weight:bold"><br>
</span></p>
<p><span style="font-weight:bold">物理机直接挂在gluster上，<span style="font-weight:bold">对自己的某个目录进行写和读：</span></span><br>
</p>
<p><span style="font-weight:bold"><span style="font-weight:bold">20G文件 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<span style="font-weight:bold">&nbsp; 1MB块大小 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 48MB/s （写） &nbsp; 106MB（读）</span></span></span></p>
<p><br>
</p>
<p><br>
</p>
<p><br>
</p>
<p>多个计算节点挂同一个卷（4个存储节点各出一个磁盘构成）。</p>
<p>计算节点个数 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;存储系统带宽</p>
<p>1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;100MB</p>
<p>2<span style="white-space:pre"> </span>200MB</p>
<p>3&nbsp;<span style="white-space:pre"> </span>240MB</p>
<p>4 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 220MB</p>
<p>3个就不行了，4个就更差了</p>
<p>这个测试告诉我们：<strong>多个节点写同一个卷可能会导致性能急速下滑</strong>。于是，我们将10个节点分别挂载在10个卷上（4个存储节点各出一个磁盘构成）</p>
<p><br>
</p>
<p>计算节点个数 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;存储系统带宽</p>
<p>10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1000MB</p>
成功，证明上述推理是正确的。
<p>由于2个节点挂同一个卷时，性能还是线性的，于是，我们将20个节点分别挂载在10个卷上（4个存储节点各出一个磁盘构成），每个卷两个计算节点</p>
<p></p>
<p>计算节点个数 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;存储系统带宽</p>
<p>20 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2000MB</p>
<p>也成功。后来经过多方测试，找到了多节点同写一个卷性能急速下滑的问题，如下所示：</p>
<p><strong>这个问题有答案了，<span style="color:#ff0000">把卷的线程数放大到64后就没问题了</span>，最大是65.我们用24个计算节点同时发起2400个进程连续写后端存储，很稳定，网络带宽达到了理想的2.4万兆，每个磁盘带宽都满了130MB左右。</strong><br>
</p>
<p><br>
</p>
<p><br>
</p>
<p>关于Stripe问题</p>
<p>经多方测试，每次写一个文件，当stripe=n时，总容量就会增大n倍，很不合理。后来进行测试，方案如下：</p>
<p>创建一个stripe=8的卷，该卷由一个存储节点的8块磁盘构成。把卷的目录mount到客户端，从客户端写文件，看看最终结果：</p>
<p><br>
</p>
<p>1）写文件的脚本：</p>
<p>#!/bin/bash<br>
for((i=0;i&lt;690000;i&#43;&#43;))<br>
&nbsp; &nbsp;do<br>
&nbsp; &nbsp; echo $i&quot;****************************&quot; &nbsp; &gt;&gt;mybd<br>
done<br>
</p>
<p>2）结果分析</p>
<p>a. 从客户端看这个文件：</p>
<p>root@s201103113:/mnt/zhxuetest# du -smh &nbsp;./mybd<br>
254M<span style="white-space:pre"> </span>./mybd</p>
<p>换个命令，看看：</p>
<p>root@s201103113:/mnt/zhxuetest# ll -h ./mybd<br>
-rw-r--r-- 1 root root 21M Jan 10 11:18 ./mybd<br>
</p>
<p>相差巨大！！！</p>
<p>把这个文件拷贝到本地目录下再看看：</p>
<p>root@s201103113:/mnt/zhxuetest# du -smh &nbsp;/tmp/mybd&nbsp;<br>
21M<span style="white-space:pre"> </span>/tmp/mybd<br>
root@s201103113:/mnt/zhxuetest# ll -h /tmp/mybd&nbsp;<br>
-rw-r--r-- 1 root root 21M Jan 10 12:12 /tmp/mybd<br>
</p>
<p>b. 从后端存储看：</p>
<p>[root@gluster001 sde]# du -smh /localdisk/sdb/3/mybd /localdisk/sdc/3/mybd /localdisk/sdd/3/mybd /localdisk/sde/3/mybd /localdisk/sdf/3/mybd /localdisk/sdg/3/mybd /localdisk/sdh/3/mybd /localdisk/sdi/3/mybd<br>
32M<span style="white-space:pre"> </span>/localdisk/sdb/3/mybd<br>
32M<span style="white-space:pre"> </span>/localdisk/sdc/3/mybd<br>
32M<span style="white-space:pre"> </span>/localdisk/sdd/3/mybd<br>
32M<span style="white-space:pre"> </span>/localdisk/sde/3/mybd<br>
33M<span style="white-space:pre"> </span>/localdisk/sdf/3/mybd<br>
33M<span style="white-space:pre"> </span>/localdisk/sdg/3/mybd<br>
33M<span style="white-space:pre"> </span>/localdisk/sdh/3/mybd<br>
32M<span style="white-space:pre"> </span>/localdisk/sdi/3/mybd<br>
[root@gluster001 sde]# ll -h /localdisk/sdb/3/mybd /localdisk/sdc/3/mybd /localdisk/sdd/3/mybd /localdisk/sde/3/mybd /localdisk/sdf/3/mybd /localdisk/sdg/3/mybd /localdisk/sdh/3/mybd /localdisk/sdi/3/mybd<br>
-rw-r--r-- 2 root root 21M Jan 10 11:18 /localdisk/sdb/3/mybd<br>
-rw-r--r-- 2 root root 21M Jan 10 11:18 /localdisk/sdc/3/mybd<br>
-rw-r--r-- 2 root root 21M Jan 10 11:18 /localdisk/sdd/3/mybd<br>
-rw-r--r-- 2 root root 21M Jan 10 11:18 /localdisk/sde/3/mybd<br>
-rw-r--r-- 2 root root 21M Jan 10 11:18 /localdisk/sdf/3/mybd<br>
-rw-r--r-- 2 root root 21M Jan 10 11:19 /localdisk/sdg/3/mybd<br>
-rw-r--r-- 2 root root 20M Jan 10 11:18 /localdisk/sdh/3/mybd<br>
-rw-r--r-- 2 root root 20M Jan 10 11:18 /localdisk/sdi/3/mybd<br>
</p>
<p><br>
</p>
<p>8个磁盘的每个文件都有大量的占位符（holes），每间隔256KB的内容就有一行holes，有些节点在开头，有些在中间。</p>
<p><br>
</p>
<p><a href="http://comments.gmane.org/gmane.comp.file-systems.gluster.user/9413">http://comments.gmane.org/gmane.comp.file-systems.gluster.user/9413</a></p>
<p></p>
<pre style="color:rgb(34,34,34); line-height:20px; text-align:justify">It's XFS doing pre-allocation of space (i.e. it doesn't expect you to leave
holes in the file, which is how glusterfs striping works). There's a mount
option to disable preallocation.

Are you sure that striping is what you want, rather than simple
distribution?  It's appropriate if you have a small number of huge files,
but if you are throwing a large number of small to medium-sized files
around, distribution may be better. Each file then sits on a single
filesystem; if you lose one brick, at least you haven't lost all your files.</pre>
<br>
<p></p>
<p><span style="color:rgb(0,0,238)"><u>http://comments.gmane.org/gmane.comp.file-systems.gluster.user/10373</u></span><br>
</p>
<p><br>
</p>
<p></p>
<pre style="color:rgb(34,34,34); line-height:20px; text-align:justify">The default stripe data layout conflicts with XFS default speculative
preallocation behavior. XFS preallocates space beyond the end of files
and the stripe translator continuously seeks past this space, making it
permanent.

You can address this by 1.) enabling the cluster.stripe-coalesce
translator option in gluster or 2.) setting the allocsize mount option
(i.e., allocsize=128k) in XFS. Note that using the latter option will
increase the likelihood of fragmentation on the backend filesystem.
</pre>
<br>
<br>
<p>使用虚拟机性能折半问题</p>
<p>OpenStack默认是none模式（如果底层支持direct IO），它每次会测试一下底层系统是否支持direct IO，因为Gluster的fuse不支持direct IO，所以它把模式改成了write_Through。我们又把模式改为write_back，性能提升到了60MB，在xml中的配置文件改不了模式，它是后面自动生成的，要改就在：<span style="font-family:微软雅黑,'MS Sans Serif',sans-serif; background-color:rgb(255,237,196)">/usr/share/pyshared/nova/virt/libvirt/connection.py</span></p>
<p><span style="font-family:微软雅黑,'MS Sans Serif',sans-serif; background-color:rgb(255,237,196)"><br>
</span></p>
<p><br>
</p>
<p><br>
</p>
<p><br>
</p>
<p><strong>1）看看Direct IO是否有用</strong></p>
<p>现在试用direct IO模式，它的优劣参见：</p>
<p><a href="http://www.makelinux.net/ldd3/chp-15-sect-3">http://www.makelinux.net/ldd3/chp-15-sect-3</a><br>
</p>
<p>在服务器上的测试结果表明和write through模式性能基本相同。比write behind慢了20MB左右。问题没解决，怎么办？继续找！！！</p>
<p><strong>2）看看异步模式是否有用</strong></p>
<p>我们写了一组测试程序，采用不同的读写模式（通过Open函数加O_sync：同步或者O_ASYNC：异步，等参数），同步、异步，发现异步比同步快很多。于是，我们觉得只要变成异步就ok。</p>
<p>我们首先用strace追踪了一下，看看虚拟机是否使用sync模式打开文件。</p>
<p>于是，满怀信心，想把KVM打开文件的模式改为Async。通过各种方式想在源码里面把aio=native加上去，都不好实现，最后利用Vm manager图形工具把它加上了。这个图形工具还不错，竟然能认到我们用openstack启动的那些虚拟机。拭目以待，迫不及待地开始测试，结果令人大失所望。和以前没什么变化。接下来，怎么办？？</p>
<p><strong>3）多线程模式（N对1：N个线程写同一个文件）</strong></p>
<p>继续测！继续想办法解决！</p>
<p>再设计一个新的测试用例，来追踪问题。</p>
<p>虚拟机vm启动后，在其所在的主机host上，查出其进程号PID，用strace 追踪PID的行为，因为不管vm做了什么，都是通过这个PID表现出来的，包括写操作。采用如下命令追踪：其中，ff可以把该进程产生的子进程也可以追出来：</p>
<p></p>
<ul>
<li class="user1li2">strace -p 22094 -f -ff -o zhxue-trace-none</li></ul>
启动后，在虚拟机里执行dd写文件操作，跑了一个1G的文件。
<p></p>
<p>跑完后，把所有日志文件拿出来解析。发现主进程派生出多个子进程（还是多线程？）去执行写操作，写的量恰好是1GB文件，接着把所有数据拿出来（知道每个子进程负责写的文件区域），自己又编写了一个多线程程序去复现KVM的操作。（具体代码见博客：你会用c写文件吗？）</p>
<p>结果发现和我们KVM虚机做的测试性能几乎完全一致。我们又把这个程序跑在一个通过NFS挂载过来的GLuster文件系统上，性能也是100MB！这说明，这个程序基本模拟出来了KVM的写模式。因此，怀疑Gluster对多线程的支持有问题，于是，google后发现：<a href="http://www.infostor.com/index/blogs_new/Henry-Newman-Blog/blogs/infostor/Henry-Newman-Blog/post987_55440010.html">http://www.infostor.com/index/blogs_new/Henry-Newman-Blog/blogs/infostor/Henry-Newman-Blog/post987_55440010.html</a>，不知道这是不是罪魁祸首？</p>
<p>后来我们又把这个程序改了改，让它的Open变为（O——Async），还是用Gluster客户端挂载，结果性能重回100MB！！！</p>
<p><br>
</p>
<p>在改Gluster native client源码之前，我们再一次尝试，更改参数看能否有效。看了Gluster文档说不支持write cache。但看到有很多cache的参数，于是更改卷的属性，重新启动卷并重新挂载卷。结果还是不理想，老问题。</p>
<p>performance.cache-max-file-size &nbsp;10GB&nbsp;<br>
performance.flush-behind<span style="white-space:pre"> </span>ON<br>
performance.write-behind-window-size &nbsp; &nbsp;2GB</p>
<p>mount -t glusterfs &nbsp;-o async gluster001:/voltest2 /tmp/zhxue/gluster001</p>
<p><br>
</p>
<p><br>
</p>
<p><br>
</p>
<p><br>
</p>
<p>春节期间我们做了一个长期测试：共启动了300多个虚机，其中170多个虚机上不停地跑IOZone，结果表明：</p>
<p>1）300多个虚机都在稳定运行；</p>
<p>2）170多个虚机上的IOZone也在持续稳定运行</p>
<p>3）后端四台存储聚合持续带宽550MB</p>
<p><br>
</p>
<p>不幸的是，春节回来后发现，性能下降很厉害，虚机只有15MB的性能，做了如下测试来判断问题所在：</p>
<p>1）物理机测试，性能还是100MB</p>
<p>&nbsp; &nbsp; &nbsp; 使用NFS重新挂载Gluster，启动虚机，性能15MB</p>
<p>&nbsp; &nbsp; &nbsp; 把GLuster弃掉，找一个计算节点作为NFS Server。把虚机映像放到上面，启动虚机，性能20MB<br>
</p>
<p><span style="white-space:pre">证明Gluster文件系统没问题。</span></p>
<p><br>
</p>
<p>2）重新找一个计算节点，重启后，启动虚机，性能15MB</p>
<p>3）重新搭建一个新的OpenStack，还是用Gluster，启动虚机，性能15MB</p>
<p><br>
</p>
<p>qemu对于cache的处理：</p>
<div>http://smilejay.com/2012/08/qemu-kvm-cache-off/<br>
</div>
<p>根据这篇文章的启示，把util/osdep.c的open函数改掉，让底层调用变为异步。这样无论上层如何，到了最后都是异步方式：</p>
<p>flags |=(!O_SYNC);</p>
<p>flags |=O_ASYNC;</p>
<p>结果没有改变！！</p>
<p><br>
</p>
<p>通过测试我们发现，</p>
<p>把一台做了Raid的服务器作为gluster服务器端。虚机性能达到100MB；</p>
<p>把一台基于SSD的服务器作为gluster服务器端。虚机性能达到100MB；</p>
<p>把一台普通服务器的tmpfs作为gluster服务器端。虚机性能达到100MB；</p>
<p>把一台做了Raid，但是raid cache为0的服务器作为gluster服务器端。虚机性能提升20%（70MB左右）；</p>
<p>把一台做了Raid，但是raid cache为0的服务器作为gluster服务器端。使用gluster协议直接挂载的虚机性能提升20%（90MB左右）；</p>
<p><br>
</p>
<p>性能问题又回到了gluster服务器端，之前我们认为服务器端的磁盘写速率在130MB，应该不是性能瓶颈，而且NFS或者物理机直接挂载都是100MB，所以注意力都放在了客户端上。现在问题又回到了gluster服务器端，<span style="color:#ff0000">这是否有矛盾？？？</span></p>
<p><br>
</p>
<p>后来发现了如下一个帖子，&#20284;乎佐证了这个办法：</p>
<p>http://lists.gnu.org/archive/html/gluster-devel/2012-05/msg00088.html</p>
<p><br>
</p>
<p><span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">ben&gt;&gt;&gt; While gluster processes do not implement write caching internally, there are at least 3 ways to improve write performance in a Gluster system.&nbsp;</span><br style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">
<span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">- If you use a RAID controller with a non-volatile writeback cache</span><span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">, the RAID controller can
 buffer writes on behalf of the Gluster server and thereby reduce latency.</span><br style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">
<span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">- XFS or any other local filesystem used within the&nbsp;</span><span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">ser</span><span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">ver
 &quot;b</span><span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">ricks&quot; can do &quot;write-thru</span><span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">&quot; caching, meaning that the writes can be aggregated and
 can be kept in the Linux buffer cache so that subsequent read requests can be satisfied from this cache, transparent to G</span><span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">luster processes.</span><br style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">
<span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">- there is a &quot;write-behind&quot; translator in the native clie</span><span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">nt that will aggregate small sequential
 write requests at the FUSE layer into larger network-level write requests. If the smallest possible application I/O size is a requirem</span><span style="color:rgb(204,0,0); font-family:'Times New Roman'; font-size:16px">ent, sequential writes can also be
 efficiently aggregated by an NFS client.</span><br>
</p>
<p>当我们把server端做成raid0后，问题有出现了，还是50MB。后来把OpenStack里面的写模式由none改成了writethrough。性能重回100MB</p>
<p><br>
</p>
<p><br>
</p>
<p><br>
</p>
<p>7.2可用性测试</p>
<p>1）关掉四台中的任何一台gluster，发现挂载在其上的虚拟机运行正常。</p>
<p>2）关掉虚拟机所挂载的具体两个gluster，发现不正常，重启其中一台gluster后，问题依旧。</p>
<p>root@new-2:/home/ubuntu# mkdir hi<br>
Segmentation fault<br>
root@new-2:/home/ubuntu# mkdir hi<br>
Segmentation fault<br>
root@new-2:/home/ubuntu# cat hi&gt;&gt;hi<br>
bash: hi: Read-only file system<br>
root@new-2:/home/ubuntu# mkdir /mnt/<br>
2gfile &nbsp; &nbsp; &nbsp;5gfile &nbsp; &nbsp; &nbsp;lost&#43;found/&nbsp;<br>
root@new-2:/home/ubuntu# mkdir /mnt/hi<br>
Segmentation fault<br>
root@new-2:/home/ubuntu# cat hi&gt;&gt;/mnt/hi<br>
cat: hi: No such file or directory<br>
root@new-2:/home/ubuntu# echo hi&gt;&gt;/mnt/hi<br>
</p>
<p><br>
</p>
<p>出现read-only file system，<span style="color:rgb(138,134,121); font-family:Arial,Helvetica,simsun,u5b8bu4f53; font-size:15px; line-height:25px">这种情况通常都是由于系统发现磁盘硬件故障或文件系统中文件被损坏之后而采取的保护机制导致的。为了保护数据不破坏分区中已有内容，Linux在挂载文件系统时就只用read-only只读方式加载了。</span></p>
<p>上述例子告诉我们：虚拟机的两个目录即根目录和/mnt目录不在同一个gluster上。</p>
<p>把根目录所在的gluster服务器启动一台后，再在根目录下进行任何操作，还是提示无权限（按理说应该一切正常）。</p>
<p>root@new-2:/home/ubuntu# echo hi &gt;&gt;hi</p>
<p><br>
bash: hi: Read-only file system<br>
</p>
<p>等了5分钟继续执行上述命令，错误依旧。把两个gluster都起来后，还是问题依旧。只好等明天再看看如何，到了第二天问题依旧。好现象，分析一下吧：</p>
<p>首先，文件是挂载在gluster上的，对于计算节点来说它是gluster的客户端，也就是说这个客户端可能缺乏NFS不断重连服务器的能力，于是研究gluster客户端看能否让其具备该能力。</p>
<p><br>
</p>
<p>1）在虚拟机上执行如下操作，均告失败</p>
<p>root@new-2:/home/ubuntu# mount -a</p>
<p>root@new-2:/home/ubuntu# echo test &gt;&gt;/test<br>
bash: /test: Read-only file system<br>
root@new-2:/home/ubuntu# mount -o remount rw /<br>
mount: you must specify the filesystem type<br>
root@new-2:/home/ubuntu# mount -t ext4 -o remount rw /<br>
mount: cannot remount block device rw read-write, is write-protected<br>
root@new-2:/home/ubuntu# mount -o remount rw /<br>
mount: you must specify the filesystem type<br>
root@new-2:/home/ubuntu# echo test &gt;&gt;/test<br>
bash: /test: Read-only file system<br>
</p>
<p><br>
</p>
<p>2）在虚拟机所在的物理节点上：</p>
<p>root@ubuntuDell:/home/yongyou# umount /var/lib/nova/instances<br>
umount: /var/lib/nova/instances: device is busy.</p>
<p><br>
</p>
<p>3）重启了虚拟机，解决。</p>
<p>当replica=2，如果两个存储节点同时坏了，之前所建的文件丢失了！。。。。</p>
<p><br>
</p>
<p>Gluster删除卷的问题</p>
<p>执行stop和delete后，再次在所在的brick上创建卷失败。</p>
<p>解决方案</p>
<p>1）在所有gluster服务器的对应brick上执行 &nbsp;for i in `attr -lq .`; do setfattr -x trusted.$i .; done&nbsp;</p>
<p>2）umount客户端所挂的老卷</p>
<p>3）在原先创建老卷的服务器上（其他gluster服务器上不行），重新创建卷</p>
<p><strong>经过多次测试，上述方案有问题（由于gluster004的安装有问题，造成干扰，在其上做先关操作都不行），不是真实原因，真正如下</strong>：</p>
<p></p>
<p>1）在所有gluster服务器的对应brick上执行 &nbsp;for i in `attr -lq .`; do setfattr -x trusted.$i .; done&nbsp;</p>
<p>2）随便一个gluster服务器上重新创建卷</p>
<p>3) &nbsp;在客户端虽然df 看不到挂载点了，但实际还在，要先umount 再mount即可</p>
<p><br>
</p>
<p><strong>关于Gluster改进的一些想法</strong></p>
<p>1）设置rep时，性能成倍递减问题</p>
<p>需要改动客户端读写流程，不能让客户端去同时写多个副本到多个gluster server上，应该只写一份，请gluster server内部去做。虽然通过nfs v3方式挂载</p>
<p>已经解决了此问题，而且把挂载的server停掉，也不会影响它的工作。但最好把客户端也改了。</p>
<p>2）rep时，容量成倍递减。</p>
<p>能否使用一些raid算法，像Panasas那样通过校验的方式把容量损失减少，比如：facebook号称他们的HDFS14个副本之占2.4多的容量？</p>
<p><br>
</p>
<p><br>
</p>
<p><br>
</p>
<p><br>
</p>

</div>

<div class="share_buttons" id="sharePanel"></div>
<!--192.168.100.34-->
<div class="article_next_prev">
    <li class="prev_article"><span>上一篇：</span><a href="/zhxue123/article/details/7950591">分布式消息总线比较</a></li>
    <li class="next_article"><span>下一篇：</span><a href="/zhxue123/article/details/7965780">一致性Hash算法</a></li>
</div>


    
</div>
<div id="ad_cen">
<script type="text/javascript" >BAIDU_CLB_SLOT_ID = "117306";</script>
<script type="text/javascript" src="http://cbjs.baidu.com/js/o.js"></script>
</div>
<script type="text/javascript">
    //new Ad(4, 'ad_cen');
</script>
<div id="comment_title" class="panel_head">查看评论<a name="comments"></a></div>
<div id="comment_list"></div>
<div id="comment_bar"></div>
<div id="comment_form"></div>
<div class="announce">* 以上用户言论只代表其个人观点，不代表CSDN网站的观点或立场<a name="reply"></a><a name="quote"></a></div>
<script type="text/javascript">
    var fileName = '7951636';
    var commentscount = 0;
    var islock = false
</script>
<script type="text/javascript" src="http://static.blog.csdn.net/scripts/comment.js"></script>
<div id="ad_bot"></div>
<script type="text/javascript">
    new Ad(5, 'ad_bot');
</script>
<div id="report_dialog"></div>

<div id="d-top" style="display:none;">
<a id="d-top-a" href="#" title="回到顶部">
<img src="http://static.blog.csdn.net/images/top.png" alt="TOP" /></a>
</div>
<script type="text/javascript">
    $(function(){
        var d_top=$('#d-top');
        document.onscroll=function(){
            var scrTop=(document.body.scrollTop||document.documentElement.scrollTop);
            if(scrTop>500){
                d_top.show();
            }else{
                d_top.hide();
            }
        }
        $('#d-top-a').click(function(){
            scrollTo(0,0);
            this.blur();
            return false;
        });
    });
</script>

<div class="clear"></div>
</div>
</div>

<div id="side">
<div class="side">
<div id="panel_Profile" class="panel">
<ul class="panel_head"><span>个人资料</span></ul>
<ul class="panel_body profile">
<div id="blog_userface">
    <a href="http://my.csdn.net/zhxue123" target="_blank">
    <img src="http://avatar.csdn.net/7/0/E/1_zhxue123.jpg" title="访问我的空间" style="max-width:90%"/>
    </a>
    <br />
    <span><a href="http://my.csdn.net/zhxue123" class="user_name" target="_blank">zhxue123</a></span>
</div>
<div class="interact">
<a href="javascript:void(0);" class="attent" id="span_add_follow" title="[加关注]"></a>
<a href="javascript:void(0);" class="letter" onclick="loginto(1)" title="[发私信]"></a>
</div>
<div id="blog_medal">
</div>
<ul id="blog_rank">
    <li>访问：<span>108899次</span></li>
    <li>积分：<span>2656分</span></li>
    <li>排名：<span>第2748名</span></li>
</ul>
<ul id="blog_statistics">
    <li>原创：<span>162篇</span></li>
    <li>转载：<span>46篇</span></li>
    <li>译文：<span>1篇</span></li>
    <li>评论：<span>13条</span></li>
</ul>
</ul>
</div>

<div class="panel">
<ul class="panel_body" style="padding:0;">
<script type="text/javascript" src="http://cbjs.baidu.com/js/m.js"></script> 
<script type="text/javascript"> 
BAIDU_CLB_preloadSlots("724643","117306"); 
</script>
<script type="text/javascript">BAIDU_CLB_fillSlot("724643");</script> 
</ul>
</div>
<div class="panel" id="panel_Search">
    <ul class="panel_head"><span>文章搜索</span></ul>
    <ul class="panel_body">
        <form id="frmSearch" action="http://so.csdn.net/search" class="form_search" target="_blank">
        <span><input id="inputSearch" type="text" class="blogsearch" title="请输入关键字" /></span>
        <input id="btnSubmit" type="submit" value="搜索" title="search in blog" />
        <input type="hidden" name="q" id="inputQ" />
        <input type="hidden" name="t" value="blog" />
        <a id="btnSearchBlog" target="_blank"></a>
        </form>
    </ul>
</div><div id="panel_Category" class="panel">
<ul class="panel_head"><span>文章分类</span></ul>
<ul class="panel_body">
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/196776">AOP</a><span>(1)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/159038">C/C++</a><span>(14)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/159035">DataBase</a><span>(4)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/763543">DataStructure and Algorithm</a><span>(3)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/535379">Design Pattern</a><span>(6)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/692518">GPU</a><span>(2)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/560494">Grid</a><span>(21)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/180683">Idea</a><span>(0)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/159033">Java</a><span>(10)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/180678">Linux</a><span>(67)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/510427">Math</a><span>(1)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/595165">Script</a><span>(3)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/549306">SOA</a><span>(2)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/867150">BigData</a><span>(28)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/549304">SoftWare</a><span>(6)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/910371">Web</a><span>(2)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/924962">Waiting List</a><span>(1)</span>
</li>
<li>
<a href="http://blog.csdn.net/zhxue123/article/category/1181998">CloudComputing</a><span>(11)</span>
</li>
</ul>
</div><div id="panel_Archive" class="panel">
<ul class="panel_head"><span>文章存档</span></ul>
<ul class="panel_body">
<div id="archive_list">
<!--归档统计-->
<li><a href="http://blog.csdn.net/zhxue123/article/month/2013/08">2013年08月</a><span>(4)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2013/07">2013年07月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2013/06">2013年06月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2013/05">2013年05月</a><span>(3)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2013/04">2013年04月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2013/03">2013年03月</a><span>(5)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2013/02">2013年02月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2013/01">2013年01月</a><span>(3)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/12">2012年12月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/11">2012年11月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/10">2012年10月</a><span>(3)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/09">2012年09月</a><span>(7)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/08">2012年08月</a><span>(4)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/07">2012年07月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/06">2012年06月</a><span>(3)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/04">2012年04月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/03">2012年03月</a><span>(4)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/02">2012年02月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2012/01">2012年01月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2011/12">2011年12月</a><span>(3)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2011/11">2011年11月</a><span>(5)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2011/10">2011年10月</a><span>(8)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2011/09">2011年09月</a><span>(6)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2011/08">2011年08月</a><span>(3)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2011/05">2011年05月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2011/03">2011年03月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2011/02">2011年02月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2011/01">2011年01月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/12">2010年12月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/11">2010年11月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/09">2010年09月</a><span>(11)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/08">2010年08月</a><span>(6)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/07">2010年07月</a><span>(4)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/06">2010年06月</a><span>(5)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/05">2010年05月</a><span>(5)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/04">2010年04月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/03">2010年03月</a><span>(3)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/02">2010年02月</a><span>(8)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2010/01">2010年01月</a><span>(3)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/12">2009年12月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/11">2009年11月</a><span>(3)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/10">2009年10月</a><span>(6)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/09">2009年09月</a><span>(8)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/08">2009年08月</a><span>(10)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/07">2009年07月</a><span>(14)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/06">2009年06月</a><span>(8)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/05">2009年05月</a><span>(4)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/04">2009年04月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2009/02">2009年02月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2008/06">2008年06月</a><span>(5)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2008/03">2008年03月</a><span>(2)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2007/08">2007年08月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2006/06">2006年06月</a><span>(1)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2006/04">2006年04月</a><span>(5)</span></li><li><a href="http://blog.csdn.net/zhxue123/article/month/2006/03">2006年03月</a><span>(5)</span></li>
</div>
</ul>
</div>
<div id="hotarticls" class="panel">
<ul class="panel_head"><span>阅读排行</span></ul>
<ul class="panel_body itemlist">
<li>
<a href="/zhxue123/article/details/7009663" title="如何查询SCI和EI检索号">如何查询SCI和EI检索号</a><span>(16136)</span>
</li>
<li>
<a href="/zhxue123/article/details/628969" title="数据挖掘和知识发现的技术、方法及应用">数据挖掘和知识发现的技术、方法及应用</a><span>(6454)</span>
</li>
<li>
<a href="/zhxue123/article/details/624227" title="vnc—server配置">vnc—server配置</a><span>(4434)</span>
</li>
<li>
<a href="/zhxue123/article/details/4465272" title="MPI的安装配置问题汇总">MPI的安装配置问题汇总</a><span>(3671)</span>
</li>
<li>
<a href="/zhxue123/article/details/5283606" title="Linux下查看cpu类型、内存大小、硬盘大小类型和文件系统大小等  ">Linux下查看cpu类型、内存大小、硬盘大小类型和文件系统大小等  </a><span>(3396)</span>
</li>
<li>
<a href="/zhxue123/article/details/4250903" title="Postgres基本命令及远程连接方案">Postgres基本命令及远程连接方案</a><span>(2491)</span>
</li>
<li>
<a href="/zhxue123/article/details/4331364" title="linux检查端口状态命令（转载，unix只能用netstat和lsof命令）">linux检查端口状态命令（转载，unix只能用netstat和lsof命令）</a><span>(2156)</span>
</li>
<li>
<a href="/zhxue123/article/details/7925178" title="程序员面试、算法研究、编程艺术、红黑树、数据挖掘5大系列集锦">程序员面试、算法研究、编程艺术、红黑树、数据挖掘5大系列集锦</a><span>(2037)</span>
</li>
<li>
<a href="/zhxue123/article/details/4659433" title="Linux下用Busy Box制作Ramdisk全过程（转帖+部分完善）">Linux下用Busy Box制作Ramdisk全过程（转帖+部分完善）</a><span>(1715)</span>
</li>
<li>
<a href="/zhxue123/article/details/4325583" title="Linux开ftp服务的简单方法">Linux开ftp服务的简单方法</a><span>(1490)</span>
</li>
</ul>
</div>
<div id="hotarticls2" class="panel">
<ul class="panel_head"><span>评论排行</span></ul>
<ul class="panel_body itemlist">
<li>
<a href="/zhxue123/article/details/7009663" title="如何查询SCI和EI检索号">如何查询SCI和EI检索号</a><span>(3)</span>
</li>
<li>
<a href="/zhxue123/article/details/6868627" title="Linux I/O及 I/O Cache">Linux I/O及 I/O Cache</a><span>(2)</span>
</li>
<li>
<a href="/zhxue123/article/details/3859512" title="服从指数分布的生成器">服从指数分布的生成器</a><span>(2)</span>
</li>
<li>
<a href="/zhxue123/article/details/4509953" title="How to install python before insalling mpich2">How to install python before insalling mpich2</a><span>(2)</span>
</li>
<li>
<a href="/zhxue123/article/details/8996420" title="VBox+Netbeans——Linux下的PHP开发环境">VBox+Netbeans——Linux下的PHP开发环境</a><span>(1)</span>
</li>
<li>
<a href="/zhxue123/article/details/5064690" title="java解决大数据读写问题">java解决大数据读写问题</a><span>(1)</span>
</li>
<li>
<a href="/zhxue123/article/details/6999985" title="CentOS 5.6 系统Python升级 和 Yum工具的修复">CentOS 5.6 系统Python升级 和 Yum工具的修复</a><span>(1)</span>
</li>
<li>
<a href="/zhxue123/article/details/4383127" title="postgreSQL和postGis安装和启动问题">postgreSQL和postGis安装和启动问题</a><span>(1)</span>
</li>
<li>
<a href="/zhxue123/article/details/6834245" title="使用Hadoop做K-Means计算的总结">使用Hadoop做K-Means计算的总结</a><span>(0)</span>
</li>
<li>
<a href="/zhxue123/article/details/6853123" title="JMS Debuger">JMS Debuger</a><span>(0)</span>
</li>
</ul>
</div>
<div id="homepageArticles" class="panel">
<ul class="panel_head"><span>推荐文章</span></ul>
<ul class="panel_body" id="ad_commend"></ul>
</div>
<script type="text/javascript">
 new Ad(12, 'ad_commend');
</script><div id="newcomments" class="panel">
<ul class="panel_head"><span>最新评论</span></ul>
<ul class="panel_body itemlist">
    <li>
    <a href="/zhxue123/article/details/7009663#comments">如何查询SCI和EI检索号</a>
    <p style="margin:0px;"><a href="/cloudeagle_bupt" class="user_name">cloudeagle_bupt</a>:
赞下薛师兄，不过Web of Science 检索号好像已经不用ISI了，WOS:XXXXX 貌似。
    </p>
    </li>
    <li>
    <a href="/zhxue123/article/details/7009663#comments">如何查询SCI和EI检索号</a>
    <p style="margin:0px;"><a href="/u011539957" class="user_name">u011539957</a>:
ISTP/CPCI  源期刊全文核心检索100%检索。QQ2846904578，组委会官网istp-...
    </p>
    </li>
    <li>
    <a href="/zhxue123/article/details/8996420#comments">VBox+Netbeans——Linux下的PHP开发环境</a>
    <p style="margin:0px;"><a href="/Rico_" class="user_name">Rico_</a>:
学习了。
    </p>
    </li>
    <li>
    <a href="/zhxue123/article/details/7009663#comments">如何查询SCI和EI检索号</a>
    <p style="margin:0px;"><a href="/zhou846775223" class="user_name">zhou846775223</a>:
不错哎
    </p>
    </li>
    <li>
    <a href="/zhxue123/article/details/6868627#comments">Linux I/O及 I/O Cache</a>
    <p style="margin:0px;"><a href="/qingheuestc" class="user_name">qingheuestc</a>:
如何调整？计算和IO做overlap？
    </p>
    </li>
    <li>
    <a href="/zhxue123/article/details/5064690#comments">java解决大数据读写问题</a>
    <p style="margin:0px;"><a href="/fengzi2009F" class="user_name">fengzi2009F</a>:
很好 用到了 java nio
    </p>
    </li>
    <li>
    <a href="/zhxue123/article/details/6999985#comments">CentOS 5.6 系统Python升级 和 Yum工具的修复</a>
    <p style="margin:0px;"><a href="/jf09mail" class="user_name">jf09mail</a>:
hao
    </p>
    </li>
    <li>
    <a href="/zhxue123/article/details/6868627#comments">Linux I/O及 I/O Cache</a>
    <p style="margin:0px;"><a href="/zhxue123" class="user_name">zhxue123</a>:
提高50%性能，很好。“对于迭代式的应用，可以通过调整文件块的读取顺序，使下次迭代可使用到一部分本次...
    </p>
    </li>
    <li>
    <a href="/zhxue123/article/details/3859512#comments">服从指数分布的生成器</a>
    <p style="margin:0px;"><a href="/gec0520" class="user_name">gec0520</a>:

    </p>
    </li>
    <li>
    <a href="/zhxue123/article/details/4383127#comments">postgreSQL和postGis安装和启动问题</a>
    <p style="margin:0px;"><a href="/匿名用户" class="user_name">匿名用户</a>:
无法连接服务器是为什么，我不知道怎么设置端口号
    </p>
    </li>
</ul>
</div>
</div>
<div class="clear"></div>
</div>

<div class="clear"></div>
</div>

<script type="text/javascript" src="http://static.blog.csdn.net/scripts/newblog.min.js?v=1.1"></script>
<script type="text/javascript" src="http://medal.blog.csdn.net/showblogmedal.ashx?blogid=98034"></script>

<script type="text/javascript">
document.write('<script type="text/javascript" src="http://csdnimg.cn/pubfooter/js/publib_footer.js?' + Math.floor(new Date()/120000).toString(36) + '="></'+'script>');
</script>

<script type="text/javascript" src="http://passport.csdn.net/content/loginbox/login.js"></script>
<script type="text/javascript">document.write("<img src=http://counter.csdn.net/pv.aspx?id=24 border=0 width=0 height=0>");</script>
<script type="text/javascript" src="http://www.csdn.net/ui/scripts/Csdn/counter.js?v=1"></script>


<script type="text/javascript" src="http://ad.csdn.net/scripts/ad-blog.js"></script>

<script type="text/javascript" src="http://zz.csdn.net/js/count.js"></script>

</div>
</body>
</html>